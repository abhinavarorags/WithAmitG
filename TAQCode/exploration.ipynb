{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17a76f8-b9d3-45f2-b1ea-a997ad8e441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory Structure\n",
    "#~/Documents/TAQData <--- has the parquet files\n",
    "#~/gitcode/AmitG/TAQCode <--- has the jupypter and python code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c7940b-4b03-4a2c-82de-777c857393f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Quotes schema:\n",
      "DATE: date32[day]\n",
      "TIME_M: time64[ns]\n",
      "EX: large_string\n",
      "BID: double\n",
      "BIDSIZ: int64\n",
      "ASK: double\n",
      "ASKSIZ: int64\n",
      "QU_COND: large_string\n",
      "QU_SEQNUM: int64\n",
      "NATBBO_IND: large_string\n",
      "QU_CANCEL: large_string\n",
      "QU_SOURCE: large_string\n",
      "SYM_ROOT: large_string\n",
      "SYM_SUFFIX: large_string\n",
      "\n",
      "ðŸ’¹ Trades schema:\n",
      "date: date32[day]\n",
      "time_m: time64[us]\n",
      "time_m_nano: int16\n",
      "ex: string\n",
      "sym_root: string\n",
      "sym_suffix: string\n",
      "tr_scond: string\n",
      "size: int32\n",
      "price: double\n",
      "tr_stop_ind: string\n",
      "tr_corr: string\n",
      "tr_seqnum: int64\n",
      "tr_id: string\n",
      "tr_source: string\n",
      "tr_rf: string\n",
      "part_time: time64[us]\n",
      "part_time_nano: int16\n",
      "trf_time: time64[us]\n",
      "trf_time_nano: int16\n",
      "tte_ind: string\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "# ---- quotes file ----\n",
    "quotes_path = '~/Documents/TAQData/data_quotes_2023_12_15.parquet'\n",
    "pf_quotes = pq.ParquetFile(quotes_path)\n",
    "print(\"ðŸ§¾ Quotes schema:\")\n",
    "print(pf_quotes.schema_arrow)     # column names and types only\n",
    "\n",
    "# ---- trades file ----\n",
    "trades_path = '~/Documents/TAQData/data_trades_2023_12_15.parquet'\n",
    "pf_trades = pq.ParquetFile(trades_path)\n",
    "print(\"\\nðŸ’¹ Trades schema:\")\n",
    "print(pf_trades.schema_arrow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca3928b-bc88-4370-bb8f-602f1a178c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes rows: 1,957,290,808\n",
      "Trades rows: 89,518,138\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Paths to your files\n",
    "quotes_path = '~/Documents/TAQData/data_quotes_2023_12_15.parquet'\n",
    "trades_path = '~/Documents/TAQData/data_trades_2023_12_15.parquet'\n",
    "\n",
    "# Efficiently count rows without loading data\n",
    "quotes_rows = pq.ParquetFile(quotes_path).metadata.num_rows\n",
    "trades_rows = pq.ParquetFile(trades_path).metadata.num_rows\n",
    "\n",
    "print(f\"Quotes rows: {quotes_rows:,}\")\n",
    "print(f\"Trades rows: {trades_rows:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53370558-e58c-42be-ba84-ce4d2ee6ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes date range: 2023-12-15 â†’ 2023-12-15\n",
      "Trades date range: 2023-12-15 â†’ 2023-12-15\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "DATA_DIR = \"~/Documents/TAQData\"\n",
    "quotes_path = os.path.expanduser(f\"{DATA_DIR}/data_quotes_2023_12_15.parquet\")\n",
    "trades_path = os.path.expanduser(f\"{DATA_DIR}/data_trades_2023_12_15.parquet\")\n",
    "\n",
    "def parquet_date_range(path, date_col):\n",
    "    pf = pq.ParquetFile(path)\n",
    "    for rg in range(pf.num_row_groups):\n",
    "        df = pf.read_row_group(rg, columns=[date_col]).to_pandas()\n",
    "        if not df.empty:\n",
    "            dmin, dmax = df[date_col].min(), df[date_col].max()\n",
    "            return dmin, dmax\n",
    "    return None, None\n",
    "\n",
    "quote_min, quote_max = parquet_date_range(quotes_path, \"DATE\")\n",
    "trade_min, trade_max = parquet_date_range(trades_path, \"date\")\n",
    "\n",
    "print(f\"Quotes date range: {quote_min} â†’ {quote_max}\")\n",
    "print(f\"Trades date range: {trade_min} â†’ {trade_max}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10878ede-05ee-4e4a-8eb4-2dfdf261d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sym_root sym_suffix     cnt\n",
      "24      AAPL       NONE  625486\n",
      "122     ADBE       NONE  140747\n",
      "1         AA       NONE  128766\n",
      "15       AAL       NONE   94629\n",
      "52       ABT       NONE   77437\n",
      "45      ABNB       NONE   76272\n",
      "133      ADI       NONE   73992\n",
      "32      ABBV       NONE   69560\n",
      "165      AEE       NONE   68983\n",
      "136      ADM       NONE   50396\n",
      "91       ACN       NONE   48587\n",
      "0          A       NONE   46061\n",
      "75      ACGL       NONE   45061\n",
      "150     ADSK       NONE   43176\n",
      "180      AEO       NONE   42705\n",
      "144      ADP       NONE   38899\n",
      "176      AEM       NONE   35980\n",
      "47       ABR       NONE   35705\n",
      "19      AAOI       NONE   35294\n",
      "10      AADI       NONE   32126\n",
      "183      AEP       NONE   30936\n",
      "21       AAP       NONE   28638\n",
      "61      ACAD       NONE   26610\n",
      "79      ACHR       NONE   26189\n",
      "82       ACI       NONE   24420\n"
     ]
    }
   ],
   "source": [
    "# 1) What symbols are actually present? (first ~20 row groups, TRADES)\n",
    "import pyarrow.parquet as pq, pandas as pd, os\n",
    "TRADES_FILE = os.path.expanduser(\"~/Documents/TAQData/data_trades_2023_12_15.parquet\")\n",
    "pf = pq.ParquetFile(TRADES_FILE)\n",
    "\n",
    "seen = []\n",
    "for rg in range(min(20, pf.num_row_groups)):\n",
    "    df = pf.read_row_group(rg, columns=[\"sym_root\",\"sym_suffix\"]).to_pandas()\n",
    "    df[\"sym_root\"]  = df[\"sym_root\"].astype(str).str.strip().str.upper()\n",
    "    df[\"sym_suffix\"]= df[\"sym_suffix\"].astype(str).fillna(\"\").str.strip().str.upper()\n",
    "    seen.append(df.groupby([\"sym_root\",\"sym_suffix\"]).size().reset_index(name=\"cnt\"))\n",
    "present = pd.concat(seen).groupby([\"sym_root\",\"sym_suffix\"])[\"cnt\"].sum().reset_index().sort_values(\"cnt\", ascending=False)\n",
    "print(present.head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca0fb98-2fc2-43e6-9c05-9ed18d25d653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#polar_try_partitioned.py for quotes and trades\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_cols(50) \n",
    "pl.Config.set_tbl_width_chars(200)\n",
    "#rename.py shall rename the cols of trades to uppercase and save since easier for joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13715247-4d0f-4b05-bf26-87a77912da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'DATE': Date, 'TIME_M': Time, 'TIME_M_NANO': Int16, 'EX': String, 'SYM_ROOT': String, 'SYM_SUFFIX': String, 'TR_SCOND': String, 'SIZE': Int32, 'PRICE': Float64, 'TR_STOP_IND': String, 'TR_CORR': String, 'TR_SEQNUM': Int64, 'TR_ID': String, 'TR_SOURCE': String, 'TR_RF': String, 'PART_TIME': Time, 'PART_TIME_NANO': Int16, 'TRF_TIME': Time, 'TRF_TIME_NANO': Int16, 'TTE_IND': String})\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# Define the directory and pattern\n",
    "directory = \"../TAQData/processed_output_trades_upper\"\n",
    "pattern = os.path.join(directory, \"chunk_*.parquet\")\n",
    "\n",
    "# Create a LazyFrame from all matching Parquet files\n",
    "lazy_df = pl.scan_parquet(pattern)\n",
    "\n",
    "# Access the schema (column names and types)\n",
    "schema = lazy_df.collect_schema()\n",
    "\n",
    "# Print the schema\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50d0961c-61e2-4aab-884a-f71a52f47979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 14)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ DATE       â”† TIME_M           â”† EX  â”† BID    â”† â€¦ â”† QU_CANCEL â”† QU_SOURCE â”† SYM_ROOT â”† SYM_SUFFIX â”‚\n",
      "â”‚ ---        â”† ---              â”† --- â”† ---    â”†   â”† ---       â”† ---       â”† ---      â”† ---        â”‚\n",
      "â”‚ date       â”† time             â”† str â”† f64    â”†   â”† str       â”† str       â”† str      â”† str        â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2023-12-15 â”† 03:59:00.1149253 â”† Z   â”† 0.0    â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 77               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 03:59:00.1854122 â”† K   â”† 0.0    â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 94               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.0044523 â”† K   â”† 197.53 â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 77               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.0044698 â”† K   â”† 197.53 â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 71               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.0045416 â”† K   â”† 197.53 â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 97               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.0045787 â”† K   â”† 197.53 â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 98               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.0046398 â”† K   â”† 197.53 â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 31               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.0046597 â”† K   â”† 197.53 â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 71               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.0047676 â”† K   â”† 197.53 â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 12               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.0047875 â”† K   â”† 197.53 â”† â€¦ â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚            â”† 46               â”†     â”†        â”†   â”†           â”†           â”†          â”†            â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "print(lazy_df.filter(pl.col(\"SYM_ROOT\") == \"AAPL\").head(10).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6613e72e-8837-4b43-8179-e1ef2c1cb246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'DATE': Date, 'TIME_M': Time, 'EX': String, 'BID': Float64, 'BIDSIZ': Int64, 'ASK': Float64, 'ASKSIZ': Int64, 'QU_COND': String, 'QU_SEQNUM': Int64, 'NATBBO_IND': String, 'QU_CANCEL': String, 'QU_SOURCE': String, 'SYM_ROOT': String, 'SYM_SUFFIX': String})\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# Define the directory and pattern\n",
    "directory = \"../TAQData/processed_output_quotes\"\n",
    "pattern = os.path.join(directory, \"chunk_*.parquet\")\n",
    "\n",
    "# Create a LazyFrame from all matching Parquet files\n",
    "lazy_df = pl.scan_parquet(pattern)\n",
    "\n",
    "# Access the schema (column names and types)\n",
    "schema = lazy_df.collect_schema()\n",
    "\n",
    "# Print the schema\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e648e6a-c81f-41f4-b5f3-e4964cf5ec5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 14)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ DATE       â”† TIME_M             â”† EX  â”† BID    â”† BIDSIZ â”† ASK    â”† ASKSIZ â”† QU_COND â”† QU_SEQNUM â”† NATBBO_IND â”† QU_CANCEL â”† QU_SOURCE â”† SYM_ROOT â”† SYM_SUFFIX â”‚\n",
      "â”‚ ---        â”† ---                â”† --- â”† ---    â”† ---    â”† ---    â”† ---    â”† ---     â”† ---       â”† ---        â”† ---       â”† ---       â”† ---      â”† ---        â”‚\n",
      "â”‚ date       â”† time               â”† str â”† f64    â”† i64    â”† f64    â”† i64    â”† str     â”† i64       â”† str        â”† str       â”† str       â”† str      â”† str        â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2023-12-15 â”† 03:59:00.114925377 â”† Z   â”† 0.0    â”† 0      â”† 0.0    â”† 0      â”† L       â”† 1103      â”† 1          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 03:59:00.185412294 â”† K   â”† 0.0    â”† 0      â”† 0.0    â”† 0      â”† L       â”† 1999      â”† 1          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.004452377 â”† K   â”† 197.53 â”† 2      â”† 0.0    â”† 0      â”† Y       â”† 3809      â”† 2          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.004469871 â”† K   â”† 197.53 â”† 2      â”† 199.38 â”† 2      â”† R       â”† 3812      â”† 4          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.004541697 â”† K   â”† 197.53 â”† 2      â”† 199.38 â”† 2      â”† R       â”† 3817      â”† 0          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.004578798 â”† K   â”† 197.53 â”† 2      â”† 199.38 â”† 2      â”† R       â”† 3819      â”† 0          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.004639831 â”† K   â”† 197.53 â”† 2      â”† 198.72 â”† 5      â”† R       â”† 3821      â”† 4          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.004659771 â”† K   â”† 197.53 â”† 2      â”† 198.5  â”† 5      â”† R       â”† 3822      â”† 4          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.004767612 â”† K   â”† 197.53 â”† 2      â”† 198.4  â”† 5      â”† R       â”† 3827      â”† 4          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â”‚ 2023-12-15 â”† 04:00:00.004787546 â”† K   â”† 197.53 â”† 2      â”† 198.3  â”† 5      â”† R       â”† 3829      â”† 4          â”† null      â”† N         â”† AAPL     â”† null       â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "print(lazy_df.filter((pl.col('SYM_ROOT') == 'AAPL') & ( pl.col('BIDSIZ').is_not_null() )).head(10).collect() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dafb3b0e-705c-4967-902c-483657072a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run query.py for joint dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
